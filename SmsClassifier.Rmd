Sms classifier
========================================================


```{r}
library("tm")
library("e1071")
library("RWeka")
library("ada")
library("caret")

setwd("C:/Users/hp/Desktop/RichaMaam/DataSet1")
print("Uploading SMS Spams and Hams!\n")
smstable<-read.csv("SMSSpamCollection", header = FALSE, sep = "\t", colClasses=c("type"="character","sms"="character"))
print("Changing column names")
colnames(smstable)<-c("type","message")

smstabletmp<-smstable

print("Extracting Ham and Spam Basic Statistics!")
smstabletmp$type[smstabletmp$type=="ham"] <- 1
smstabletmp$type[smstabletmp$type=="spam"] <- 0


#Convert character data into numeric
tmp<-as.numeric(smstabletmp$type)

#Basic Statisctics like mean and variance of spam and hams
hamavg<-mean(tmp)
print("Average Ham is :");hamavg

hamvariance<-var(tmp)
print("Var of Ham is :");hamvariance

print("Extract average token of Hams and Spams!")

nohamtokens<-0
noham<-0
nospamtokens<-0
nospam<-0

for(i in 1:length(smstable$type)){
  if(smstable[i,1]=="ham"){
    nohamtokens<-length(strsplit(smstable[i,2], "\\s+")[[1]])+nohamtokens
    noham<-noham+1
  }else{ 
    nospamtokens<-length(strsplit(smstable[i,2], "\\s+")[[1]])+nospamtokens
    nospam<-nospam+1
  }
}

totaltokens<-nospamtokens+nohamtokens;
print("total number of tokens is:")
print(totaltokens)

avgtokenperham<-nohamtokens/noham
print("Avarage number of tokens per ham message")
print(avgtokenperham)

avgtokenperspam<-nospamtokens/nospam
print("Avarage number of tokens per spam message")
print(avgtokenperspam)
```

```{r}
print(" Make two different sets, training data and test data!")

inTrain<-createDataPartition(y=smstable$type,p=0.75,list=FALSE)
training<-smstable[inTrain,]
testing<-smstable[-inTrain,]

trdata<-training
tedata<-testing

# Text feature extraction using tm package

trsmses<-Corpus(VectorSource(trdata[,2]))
trsmses<-tm_map(trsmses, stripWhitespace)
trsmses<-tm_map(trsmses, content_transformer(tolower))
trsmses<-tm_map(trsmses, removeWords, stopwords("english"))

dtm <- DocumentTermMatrix(trsmses)
#These highly used words are used as an index to make VSM 
#(vector space model) for trained data and test data
highlyrepeatedwords<-findFreqTerms(dtm, 80)


set.seed(1245)
#This function makes vector (Vector Space Model) from text message using highly repeated words
vsm<-function(message,highlyrepeatedwords){
tokenizedmessage<-strsplit(message, "\\s+")[[1]]
#making vector
v<-rep(0,length(highlyrepeatedwords))
for(i in 1:length(highlyrepeatedwords))
{
  for(j in 1:length(tokenizedmessage))
  {
    if(highlyrepeatedwords[i]==tokenizedmessage[j])
    {
      v[i]<-v[i]+1
    }
  }
}
return (v)
}
#vectorized training data set
vtrdata=NULL

#vectorized test data set 
vtedata=NULL

#Creating vectorised training and testing data sets
for(i in 1:length(trdata[,2])){
  if(trdata[i,1]=="ham"){
    vtrdata=rbind(vtrdata,c(1,vsm(trdata[i,2],highlyrepeatedwords)))
  }
  else{
    vtrdata=rbind(vtrdata,c(0,vsm(trdata[i,2],highlyrepeatedwords)))
  }
  
}

for(i in 1:length(tedata[,2])){
  if(tedata[i,1]=="ham"){
    vtedata=rbind(vtedata,c(1,vsm(tedata[i,2],highlyrepeatedwords)))
  }
  else{
    vtedata=rbind(vtedata,c(0,vsm(tedata[i,2],highlyrepeatedwords)))
  }
  
}
# Run different classification algorithms

("----------------------------------KNN-----------------------------------------") 
data<-data.frame(sms=vtrdata[,2:length(vtrdata[1,])],type=vtrdata[,1])
testdata<-data.frame(sms=vtedata[,2:length(vtedata[1,])],type=vtedata[,1])
knnmodel<-train(data,data$type,method="knn",warnings =FALSE)
knnpredicttest<-predict(knnmodel,testdata)

for(i in 1:length(knnpredicttest))
{
  if(knnpredicttest[i]>0.5)
    knnpredicttest[i]=1
  else
    knnpredicttest[i]=0
}
print("Confusion Matrix for the model using knn method is:")
confusionMatrix(knnpredicttest,vtedata[,1])



```

